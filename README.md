# ğŸŒ OffGrid LLM

**AI for Edge & Offline Environments**

OffGrid LLM is a lightweight, offline-first LLM orchestrator designed for environments with limited or intermittent internet connectivity. Built in Go for maximum performance and minimal resource usage.

## ğŸ¯ Features

- âœ… **Offline-First**: Works without internet connectivity
- ğŸ”„ **P2P Model Sharing**: Share models across local networks
- ğŸ’¾ **USB Model Import**: Install models from USB drives/SD cards
- âš¡ **Low Resource**: Runs on devices with as little as 2GB RAM
- ğŸ”Œ **OpenAI-Compatible API**: Drop-in replacement for OpenAI API
- ğŸŒ **Edge-Ready**: Perfect for remote locations, ships, clinics, schools
- ğŸ“¦ **Single Binary**: Easy deployment, no dependencies

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/takuphilchan/offgrid-llm.git
cd offgrid-llm

# Quick start (builds and optionally downloads a model)
./scripts/quickstart.sh

# Or manually:
# Build
make build

# Run
./offgrid
```

Server will start on `http://localhost:8080`

See [Model Setup Guide](docs/MODEL_SETUP.md) for downloading models.

## ğŸ“š API Endpoints

```
GET  /health                  - Health check
GET  /v1/models              - List available models
POST /v1/chat/completions    - Chat completions (OpenAI-compatible)
POST /v1/completions         - Text completions (OpenAI-compatible)
```

## ğŸ—ï¸ Architecture

```
offgrid-llm/
â”œâ”€â”€ cmd/offgrid/           # Main application entry point
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ server/           # HTTP server & API handlers
â”‚   â”œâ”€â”€ models/           # Model management & registry
â”‚   â”œâ”€â”€ inference/        # LLM inference engine
â”‚   â”œâ”€â”€ resource/         # Resource monitoring & allocation
â”‚   â””â”€â”€ p2p/              # Peer-to-peer networking
â”œâ”€â”€ pkg/api/              # Public API types
â””â”€â”€ web/ui/               # Web dashboard (future)
```

## ğŸ¯ Use Cases

- ğŸš¢ **Maritime & Offshore** - Ships, oil rigs, research vessels
- ğŸ¥ **Healthcare** - Rural clinics, mobile medical units
- ğŸ« **Education** - Schools in low-bandwidth areas
- ğŸ­ **Industrial** - Factories, mines, warehouses
- ğŸ”’ **High-Security** - Air-gapped networks
- ğŸ•ï¸ **Field Research** - Remote scientific operations

## ğŸ›£ï¸ Roadmap

### Phase 1 âœ… (Completed)
- [x] Basic HTTP server
- [x] OpenAI-compatible API structure
- [x] Model registry and management
- [x] Resource monitoring
- [x] Configuration system
- [x] P2P discovery foundation
- [x] Unit tests

### Phase 2 (In Progress)
- [ ] llama.cpp integration
- [ ] Model loading from disk
- [ ] P2P model discovery & sharing
- [ ] USB model import API
- [ ] Multi-user support

### Phase 3
- [ ] Advanced quantization
- [ ] Bandwidth-aware syncing
- [ ] Web dashboard
- [ ] Mobile/ARM optimization
- [ ] Docker support

## ğŸ“– Documentation

- [Model Setup Guide](docs/MODEL_SETUP.md) - Download and configure models
- [Quick Start Script](scripts/quickstart.sh) - Automated setup

## ğŸ§ª Testing

```bash
# Run tests
make test

# Build
make build

# Run in development mode
make dev
```

## ğŸ¤ Contributing

Contributions welcome! This project aims to make AI accessible in underserved environments.

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ’¡ Philosophy

**AI should work everywhere, not just where the internet is fast.**

OffGrid LLM brings powerful language models to edge environments, remote locations, and anywhere reliable internet connectivity isn't guaranteed.
