Metadata-Version: 2.1
Name: offgrid
Version: 0.1.0
Summary: Python client for OffGrid LLM - Run AI models completely offline
Author-email: OffGrid LLM Team <team@offgrid-llm.dev>
Maintainer-email: OffGrid LLM Team <team@offgrid-llm.dev>
License: MIT
Project-URL: Homepage, https://github.com/takuphilchan/offgrid-llm
Project-URL: Documentation, https://github.com/takuphilchan/offgrid-llm/tree/main/python
Project-URL: Repository, https://github.com/takuphilchan/offgrid-llm
Project-URL: Issues, https://github.com/takuphilchan/offgrid-llm/issues
Keywords: llm,ai,offline,local,inference,llama,gguf,machine-learning,nlp,chatbot
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Provides-Extra: dev
Requires-Dist: pytest>=7.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0; extra == "dev"
Requires-Dist: black>=23.0; extra == "dev"
Requires-Dist: isort>=5.0; extra == "dev"
Requires-Dist: mypy>=1.0; extra == "dev"

# OffGrid Python Client

Python client for [OffGrid LLM](https://github.com/takuphilchan/offgrid-llm) - Run AI models completely offline.

## Installation

```bash
pip install offgrid
```

## Quick Start

```python
import offgrid

client = offgrid.Client()
response = client.chat("Hello!")
print(response)
```

## Usage

### Connect to Server

```python
import offgrid

# Default: localhost:11611
client = offgrid.Client()

# Custom server
client = offgrid.Client(host="http://192.168.1.100:11611")

# With timeout
client = offgrid.Client(host="http://192.168.1.100:11611", timeout=600)
```

### Chat

```python
# Basic
response = client.chat("What is Python?")

# With system prompt
response = client.chat(
    "Write a poem",
    system="You are a poet",
    temperature=0.9
)

# Streaming
for chunk in client.chat("Tell me a story", stream=True):
    print(chunk, end="", flush=True)

# Full conversation
messages = [
    {"role": "system", "content": "You are helpful."},
    {"role": "user", "content": "Hello!"},
]
response = client.chat(messages=messages)
```

### Model Management

```python
# List installed models
for model in client.list_models():
    print(model["id"])

# Search HuggingFace
results = client.models.search("llama", ram=8)
for r in results:
    print(f"{r['id']} - {r['size_gb']}GB")

# Download
client.models.download(
    "bartowski/Llama-3.2-3B-Instruct-GGUF",
    "Llama-3.2-3B-Instruct-Q4_K_M.gguf"
)

# Delete
client.models.delete("old-model")

# USB import/export
client.models.import_usb("/media/usb")
client.models.export_usb("model-name", "/media/usb")
```

### Knowledge Base (RAG)

```python
# Add documents
client.kb.add("notes.txt")
client.kb.add("meeting", content="Meeting notes...")
client.kb.add_directory("./docs")

# List
for doc in client.kb.list():
    print(f"{doc['id']}: {doc['chunks']} chunks")

# Search
results = client.kb.search("deadline")

# Chat with context
response = client.chat("Summarize notes", use_kb=True)

# Remove
client.kb.remove("notes.txt")
client.kb.clear()
```

### Embeddings

```python
# Single
embedding = client.embed("Hello world")

# Batch
embeddings = client.embed(["Hello", "World"])
```

### System Info

```python
# Health check
if client.health():
    print("Server running")

# Detailed info
info = client.info()
print(f"Uptime: {info['uptime']}")
```

## Error Handling

```python
from offgrid import Client, OffGridError

client = Client()

try:
    response = client.chat("Hello")
except OffGridError as e:
    print(f"Error: {e.message}")
```

## Requirements

- Python 3.8+
- OffGrid server running (`offgrid serve`)
- No external dependencies

## Links

- [OffGrid LLM](https://github.com/takuphilchan/offgrid-llm)
- [API Reference](https://github.com/takuphilchan/offgrid-llm/blob/main/docs/API.md)

## License

MIT License
