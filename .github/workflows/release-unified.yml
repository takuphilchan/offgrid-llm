name: Release

on:
  push:
    tags: ['v*']
  workflow_dispatch:
    inputs:
      version:
        description: 'Version to release (e.g., v1.0.0)'
        required: true
        type: string

permissions:
  contents: write

env:
  GO_VERSION: '1.21'

jobs:
  # Create release first
  create-release:
    name: Create Release
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/') || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Get version
        id: version
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "version=${{ github.event.inputs.version }}" >> $GITHUB_OUTPUT
          else
            echo "version=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT
          fi
      
      - name: Delete existing release if present
        continue-on-error: true
        run: |
          gh release delete ${{ steps.version.outputs.version }} --yes --repo ${{ github.repository }} || true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Create new release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ steps.version.outputs.version }}
          name: OffGrid LLM ${{ steps.version.outputs.version }}
          body: |
            # OffGrid LLM ${{ steps.version.outputs.version }}
            
            Release is being built. Artifacts will appear shortly.
            
            Please wait for all build jobs to complete.
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Build complete bundles with offgrid + llama-server
  build-bundles:
    name: Build ${{ matrix.name }}
    runs-on: ${{ matrix.os }}
    needs: create-release
    strategy:
      fail-fast: false
      matrix:
        include:
          # Linux CPU builds on Ubuntu 22.04 (GLIBC 2.35 - wide compatibility)
          - name: linux-amd64-cpu-avx2
            os: ubuntu-22.04
            platform: linux
            arch: amd64
            variant: cpu
            cpu_features: avx2
            gpu_flags: ""
            cpu_flags: "-march=x86-64-v3 -mno-avx512f"
            
          - name: linux-amd64-cpu-avx512
            os: ubuntu-22.04
            platform: linux
            arch: amd64
            variant: cpu
            cpu_features: avx512
            gpu_flags: ""
            cpu_flags: "-march=x86-64-v4"
            
          - name: linux-arm64-cpu
            os: ubuntu-22.04
            platform: linux
            arch: arm64
            variant: cpu
            cpu_features: neon
            gpu_flags: ""
            cpu_flags: "-march=armv8-a"
          
          # Linux Vulkan builds on Ubuntu 24.04 (GLIBC 2.38 - GPU acceleration)
          - name: linux-amd64-vulkan-avx2
            os: ubuntu-24.04
            platform: linux
            arch: amd64
            variant: vulkan
            cpu_features: avx2
            gpu_flags: "-DGGML_VULKAN=ON"
            cpu_flags: "-march=x86-64-v3 -mno-avx512f"
            
          - name: linux-amd64-vulkan-avx512
            os: ubuntu-24.04
            platform: linux
            arch: amd64
            variant: vulkan
            cpu_features: avx512
            gpu_flags: "-DGGML_VULKAN=ON"
            cpu_flags: "-march=x86-64-v4"
            
          # macOS variants
          - name: darwin-arm64-metal
            os: macos-latest
            platform: darwin
            arch: arm64
            variant: metal
            cpu_features: apple-silicon
            gpu_flags: "-DGGML_METAL=ON"
            cpu_flags: "-mcpu=apple-m1"
            
          - name: darwin-amd64-cpu
            os: macos-15
            platform: darwin
            arch: amd64
            variant: cpu
            cpu_features: avx2
            gpu_flags: ""
            cpu_flags: "-march=x86-64-v3 -mno-avx512f"
            
          # Windows variants
          - name: windows-amd64-cpu
            os: windows-latest
            platform: windows
            arch: amd64
            variant: cpu
            cpu_features: avx2
            gpu_flags: ""
            cpu_flags: "-march=x86-64-v3 -mno-avx512f"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}

      - name: Get version
        id: version
        shell: bash
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "version=${{ github.event.inputs.version }}" >> $GITHUB_OUTPUT
          else
            echo "version=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT
          fi

      - name: Install dependencies (Linux)
        if: matrix.platform == 'linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential cmake git
          
          # Install Vulkan SDK if needed
          if [ "${{ matrix.variant }}" = "vulkan" ]; then
            # Install Vulkan SDK from LunarG for glslc
            # Detect Ubuntu version and use correct repo
            UBUNTU_CODENAME=$(lsb_release -cs)
            wget -qO- https://packages.lunarg.com/lunarg-signing-key-pub.asc | sudo tee /etc/apt/trusted.gpg.d/lunarg.asc
            sudo wget -qO /etc/apt/sources.list.d/lunarg-vulkan.list "https://packages.lunarg.com/vulkan/lunarg-vulkan-${UBUNTU_CODENAME}.list"
            sudo apt-get update
            sudo apt-get install -y vulkan-sdk
          fi

      - name: Install dependencies (macOS)
        if: matrix.platform == 'darwin'
        run: |
          brew install cmake

      - name: Install dependencies (Windows)
        if: matrix.platform == 'windows'
        shell: bash
        run: |
          choco install cmake --installargs 'ADD_CMAKE_TO_PATH=System'
          choco install mingw

      - name: Clone llama.cpp
        shell: bash
        run: |
          git clone --depth 1 https://github.com/ggml-org/llama.cpp /tmp/llama.cpp
          cd /tmp/llama.cpp
          echo "LLAMA_COMMIT=$(git rev-parse --short HEAD)" >> $GITHUB_ENV

      - name: Build llama-server
        shell: bash
        run: |
          cd /tmp/llama.cpp
          mkdir build && cd build
          
          # Detect host architecture and validate CPU flags compatibility
          HOST_ARCH="$(uname -m)"
          MATRIX_CPU_FLAGS="${{ matrix.cpu_flags }}"
          
          echo "Host architecture: $HOST_ARCH"
          echo "Matrix CPU flags: $MATRIX_CPU_FLAGS"
          
          # Clear CPU_FLAGS by default, only set if compatible
          CPU_FLAGS=""
          
          # Only apply CPU flags if they match the host architecture
          case "$HOST_ARCH" in
            x86_64|amd64)
              # Only use flags if they're x86-related
              if echo "$MATRIX_CPU_FLAGS" | grep -qE 'x86|x86-64|v3|v4|haswell|native'; then
                CPU_FLAGS="$MATRIX_CPU_FLAGS"
                echo "Using x86 CPU flags: $CPU_FLAGS"
              else
                echo "Skipping incompatible CPU flags for x86_64 host"
              fi
              ;;
            aarch64|arm64)
              # Only use flags if they're ARM-related
              if echo "$MATRIX_CPU_FLAGS" | grep -qE 'arm|aarch64|armv|apple'; then
                CPU_FLAGS="$MATRIX_CPU_FLAGS"
                echo "Using ARM CPU flags: $CPU_FLAGS"
              else
                echo "Skipping incompatible CPU flags for ARM host"
              fi
              ;;
            *)
              echo "Unknown architecture: $HOST_ARCH - skipping CPU flags"
              ;;
          esac
          
          # Build CMake command with validated flags
          # Use static linking for maximum GLIBC compatibility (works on GLIBC 2.17+)
          CMAKE_ARGS="-DBUILD_SHARED_LIBS=OFF -DCMAKE_BUILD_TYPE=Release -DGGML_STATIC=ON -DLLAMA_CURL=OFF"
          
          # Add static linking flags for Linux to avoid GLIBC version requirements
          if [ "${{ matrix.platform }}" = "linux" ]; then
            STATIC_FLAGS="-static-libgcc -static-libstdc++"
            if [ -n "$CPU_FLAGS" ]; then
              CMAKE_ARGS="$CMAKE_ARGS -DCMAKE_C_FLAGS=\"$CPU_FLAGS $STATIC_FLAGS\" -DCMAKE_CXX_FLAGS=\"$CPU_FLAGS $STATIC_FLAGS\""
              CMAKE_ARGS="$CMAKE_ARGS -DCMAKE_EXE_LINKER_FLAGS=\"$STATIC_FLAGS\""
            else
              CMAKE_ARGS="$CMAKE_ARGS -DCMAKE_C_FLAGS=\"$STATIC_FLAGS\" -DCMAKE_CXX_FLAGS=\"$STATIC_FLAGS\""
              CMAKE_ARGS="$CMAKE_ARGS -DCMAKE_EXE_LINKER_FLAGS=\"$STATIC_FLAGS\""
            fi
            echo "Using static linking for Linux (GLIBC compatibility)"
          elif [ -n "$CPU_FLAGS" ]; then
            CMAKE_ARGS="$CMAKE_ARGS -DCMAKE_C_FLAGS=\"$CPU_FLAGS\" -DCMAKE_CXX_FLAGS=\"$CPU_FLAGS\""
            echo "CMake will use CPU optimizations: $CPU_FLAGS"
          else
            echo "CMake will use default compiler flags (no CPU-specific optimizations)"
          fi
          
          # Add GPU flags if present
          if [ -n "${{ matrix.gpu_flags }}" ]; then
            CMAKE_ARGS="$CMAKE_ARGS ${{ matrix.gpu_flags }}"
          fi
          
          # Run cmake
          echo "Running: cmake .. $CMAKE_ARGS"
          eval cmake .. $CMAKE_ARGS
          
          cmake --build . --config Release -j $(nproc 2>/dev/null || sysctl -n hw.ncpu 2>/dev/null || echo 4) --target llama-server

      - name: Build whisper.cpp
        shell: bash
        run: |
          git clone --depth 1 https://github.com/ggml-org/whisper.cpp /tmp/whisper.cpp
          cd /tmp/whisper.cpp
          echo "WHISPER_COMMIT=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
          
          mkdir build && cd build
          
          # Build with static linking for Linux (GLIBC compatibility)
          CMAKE_ARGS="-DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF"
          if [ "${{ matrix.platform }}" = "linux" ]; then
            STATIC_FLAGS="-static-libgcc -static-libstdc++"
            CMAKE_ARGS="$CMAKE_ARGS -DCMAKE_C_FLAGS=\"$STATIC_FLAGS\" -DCMAKE_CXX_FLAGS=\"$STATIC_FLAGS\""
            CMAKE_ARGS="$CMAKE_ARGS -DCMAKE_EXE_LINKER_FLAGS=\"$STATIC_FLAGS\""
          fi
          
          eval cmake .. $CMAKE_ARGS
          cmake --build . --config Release -j $(nproc 2>/dev/null || sysctl -n hw.ncpu 2>/dev/null || echo 4)

      - name: Download Piper
        shell: bash
        run: |
          mkdir -p /tmp/piper
          cd /tmp/piper
          
          PLATFORM="${{ matrix.platform }}"
          ARCH="${{ matrix.arch }}"
          
          # Construct download URL based on platform/arch
          if [ "$PLATFORM" = "linux" ]; then
            if [ "$ARCH" = "amd64" ]; then
              PIPER_URL="https://github.com/rhasspy/piper/releases/download/2023.11.14-2/piper_linux_x86_64.tar.gz"
            else
              PIPER_URL="https://github.com/rhasspy/piper/releases/download/2023.11.14-2/piper_linux_aarch64.tar.gz"
            fi
          elif [ "$PLATFORM" = "darwin" ]; then
            if [ "$ARCH" = "arm64" ]; then
              PIPER_URL="https://github.com/rhasspy/piper/releases/download/2023.11.14-2/piper_macos_aarch64.tar.gz"
            else
              PIPER_URL="https://github.com/rhasspy/piper/releases/download/2023.11.14-2/piper_macos_x64.tar.gz"
            fi
          elif [ "$PLATFORM" = "windows" ]; then
            PIPER_URL="https://github.com/rhasspy/piper/releases/download/2023.11.14-2/piper_windows_amd64.zip"
          fi
          
          echo "Downloading Piper from: $PIPER_URL"
          
          # Retry logic for transient network errors (502, etc)
          for i in 1 2 3 4 5; do
            if curl -fsSL --retry 3 --retry-delay 5 -o piper-archive "$PIPER_URL"; then
              echo "Download successful on attempt $i"
              break
            else
              echo "Attempt $i failed, retrying in 10 seconds..."
              sleep 10
            fi
          done
          
          if [ ! -f piper-archive ]; then
            echo "Failed to download Piper after 5 attempts"
            exit 1
          fi
          
          if [[ "$PIPER_URL" == *.zip ]]; then
            unzip piper-archive
          else
            tar -xzf piper-archive
          fi

      - name: Build offgrid binary
        shell: bash
        env:
          GOOS: ${{ matrix.platform }}
          GOARCH: ${{ matrix.arch }}
          CGO_ENABLED: 0
        run: |
          VERSION="${{ steps.version.outputs.version }}"
          BUILD_TIME=$(date -u '+%Y-%m-%d_%H:%M:%S')
          
          go build \
            -ldflags="-s -w -X main.Version=${VERSION} -X main.BuildTime=${BUILD_TIME}" \
            -o offgrid${{ matrix.platform == 'windows' && '.exe' || '' }} \
            ./cmd/offgrid

      - name: Create bundle
        shell: bash
        run: |
          VERSION="${{ steps.version.outputs.version }}"
          BUNDLE_NAME="offgrid-${VERSION}-${{ matrix.platform }}-${{ matrix.arch }}-${{ matrix.variant }}-${{ matrix.cpu_features }}"
          
          mkdir -p "$BUNDLE_NAME"
          mkdir -p "$BUNDLE_NAME/audio/whisper"
          mkdir -p "$BUNDLE_NAME/audio/piper"
          
          # Copy main binaries
          if [ "${{ matrix.platform }}" = "windows" ]; then
            cp offgrid.exe "$BUNDLE_NAME/"
            cp /tmp/llama.cpp/build/bin/Release/llama-server.exe "$BUNDLE_NAME/" 2>/dev/null || \
              cp /tmp/llama.cpp/build/bin/llama-server.exe "$BUNDLE_NAME/"
            
            # Copy whisper binary
            cp /tmp/whisper.cpp/build/bin/Release/whisper-cli.exe "$BUNDLE_NAME/audio/whisper/" 2>/dev/null || \
              cp /tmp/whisper.cpp/build/bin/whisper-cli.exe "$BUNDLE_NAME/audio/whisper/" 2>/dev/null || true
            
            # Copy piper
            cp -r /tmp/piper/piper/* "$BUNDLE_NAME/audio/piper/" 2>/dev/null || \
              cp /tmp/piper/piper.exe "$BUNDLE_NAME/audio/piper/" 2>/dev/null || true
          else
            cp offgrid "$BUNDLE_NAME/"
            cp /tmp/llama.cpp/build/bin/llama-server "$BUNDLE_NAME/"
            
            # Copy whisper binary and libs
            cp /tmp/whisper.cpp/build/bin/whisper-cli "$BUNDLE_NAME/audio/whisper/"
            cp /tmp/whisper.cpp/build/src/*.so* "$BUNDLE_NAME/audio/whisper/" 2>/dev/null || \
              cp /tmp/whisper.cpp/build/src/*.dylib "$BUNDLE_NAME/audio/whisper/" 2>/dev/null || true
            cp /tmp/whisper.cpp/build/ggml/src/*.so* "$BUNDLE_NAME/audio/whisper/" 2>/dev/null || \
              cp /tmp/whisper.cpp/build/ggml/src/*.dylib "$BUNDLE_NAME/audio/whisper/" 2>/dev/null || true
            
            # Create whisper wrapper script
            if [ "${{ matrix.platform }}" = "linux" ]; then
              printf '%s\n' '#!/bin/bash' 'SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"' 'export LD_LIBRARY_PATH="$SCRIPT_DIR:$LD_LIBRARY_PATH"' 'exec "$SCRIPT_DIR/whisper-cli" "$@"' > "$BUNDLE_NAME/audio/whisper/whisper"
            elif [ "${{ matrix.platform }}" = "darwin" ]; then
              printf '%s\n' '#!/bin/bash' 'SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"' 'export DYLD_LIBRARY_PATH="$SCRIPT_DIR:$DYLD_LIBRARY_PATH"' 'exec "$SCRIPT_DIR/whisper-cli" "$@"' > "$BUNDLE_NAME/audio/whisper/whisper"
            fi
            chmod +x "$BUNDLE_NAME/audio/whisper/whisper" "$BUNDLE_NAME/audio/whisper/whisper-cli"
            
            # Copy piper
            cp -r /tmp/piper/piper/* "$BUNDLE_NAME/audio/piper/" 2>/dev/null || \
              cp /tmp/piper/piper "$BUNDLE_NAME/audio/piper/" 2>/dev/null || true
            chmod +x "$BUNDLE_NAME/audio/piper/"* 2>/dev/null || true
          fi
          
          # Create install script
          if [ "${{ matrix.platform }}" != "windows" ]; then
            cat > "$BUNDLE_NAME/install.sh" << 'EOF'
          #!/bin/bash
          set -e
          SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
          AUDIO_DIR="$HOME/.offgrid-llm/audio"
          
          echo "Installing OffGrid LLM..."
          
          # Install main binaries
          sudo cp "$SCRIPT_DIR/offgrid" /usr/local/bin/offgrid
          sudo cp "$SCRIPT_DIR/llama-server" /usr/local/bin/llama-server
          sudo chmod +x /usr/local/bin/offgrid /usr/local/bin/llama-server
          
          # Install audio components
          echo "Installing audio components..."
          mkdir -p "$AUDIO_DIR/whisper" "$AUDIO_DIR/piper"
          
          if [ -d "$SCRIPT_DIR/audio/whisper" ]; then
            cp -r "$SCRIPT_DIR/audio/whisper/"* "$AUDIO_DIR/whisper/"
            chmod +x "$AUDIO_DIR/whisper/"* 2>/dev/null || true
            echo "âœ“ Whisper (speech-to-text) installed"
          fi
          
          if [ -d "$SCRIPT_DIR/audio/piper" ]; then
            cp -r "$SCRIPT_DIR/audio/piper/"* "$AUDIO_DIR/piper/"
            chmod +x "$AUDIO_DIR/piper/"* 2>/dev/null || true
            echo "âœ“ Piper (text-to-speech) installed"
          fi
          
          # Install web UI
          WEB_DIR="/var/lib/offgrid/web/ui"
          if [ -d "$SCRIPT_DIR/web/ui" ]; then
            sudo mkdir -p "$WEB_DIR"
            sudo cp -r "$SCRIPT_DIR/web/ui/"* "$WEB_DIR/"
            echo "âœ“ Web UI installed"
          fi
          
          echo ""
          echo "âœ“ OffGrid LLM installed successfully!"
          echo ""
          echo "Get started:"
          echo "  offgrid --version"
          echo "  offgrid serve              # Start server with Web UI"
          echo "  offgrid search llama       # Search for models"
          EOF
            chmod +x "$BUNDLE_NAME/install.sh"
          fi
          
          # Copy web UI to bundle
          if [ -d "web/ui" ]; then
            mkdir -p "$BUNDLE_NAME/web/ui"
            cp -r web/ui/* "$BUNDLE_NAME/web/ui/"
          fi
          
          # Create README
          cat > "$BUNDLE_NAME/README.md" << EOF
          # OffGrid LLM ${VERSION}
          
          **Platform:** ${{ matrix.name }}
          **llama.cpp:** ${{ env.LLAMA_COMMIT }}
          **whisper.cpp:** ${{ env.WHISPER_COMMIT }}
          
          ## Installation
          EOF
          
          if [ "${{ matrix.platform }}" = "windows" ]; then
            cat >> "$BUNDLE_NAME/README.md" << 'EOF'
          ### Windows
          1. Extract this archive
          2. Run the installer or manually copy binaries to your PATH
          
          ```powershell
          # Copy main binaries
          Copy-Item offgrid.exe C:\Program Files\OffGrid\
          Copy-Item llama-server.exe C:\Program Files\OffGrid\
          
          # Audio binaries are in audio\ folder
          ```
          EOF
          else
            cat >> "$BUNDLE_NAME/README.md" << 'EOF'
          ### Linux / macOS
          ```bash
          ./install.sh
          ```
          
          This installs:
          - offgrid and llama-server to /usr/local/bin
          - whisper.cpp and piper to ~/.offgrid-llm/audio/
          - Web UI to /var/lib/offgrid/web/ui/
          EOF
          fi
          
          cat >> "$BUNDLE_NAME/README.md" << 'EOF'
          
          ## Getting Started
          
          ```bash
          # Verify installation
          offgrid --version
          
          # Start server with Web UI
          offgrid serve
          
          # Search for models
          offgrid search llama --limit 5
          
          # Download a model
          offgrid download-hf bartowski/Llama-3.2-3B-Instruct-GGUF \
            --file Llama-3.2-3B-Instruct-Q4_K_M.gguf
          
          # Start chatting
          offgrid run Llama-3.2-3B-Instruct-Q4_K_M
          ```
          
          ## Features
          
          - **LLM Inference**: Chat with local AI models
          - **Speech-to-Text**: Transcribe audio with whisper.cpp
          - **Text-to-Speech**: Generate speech with Piper
          - **Web UI**: Access at http://localhost:11611/ui
          
          ## Documentation
          
          https://github.com/takuphilchan/offgrid-llm
          EOF
          
          # Create checksums (use shasum on macOS, sha256sum on Linux)
          cd "$BUNDLE_NAME"
          if [ "${{ matrix.platform }}" = "windows" ]; then
            sha256sum offgrid.exe llama-server.exe > checksums.sha256 2>/dev/null || \
              shasum -a 256 offgrid.exe llama-server.exe > checksums.sha256
          elif [ "${{ matrix.platform }}" = "darwin" ]; then
            shasum -a 256 offgrid llama-server > checksums.sha256
          else
            sha256sum offgrid llama-server > checksums.sha256
          fi
          cd ..
          
          # Create archive
          if [ "${{ matrix.platform }}" = "windows" ]; then
            powershell Compress-Archive -Path "$BUNDLE_NAME" -DestinationPath "${BUNDLE_NAME}.zip"
            echo "ASSET_PATH=${BUNDLE_NAME}.zip" >> $GITHUB_ENV
          else
            tar -czf "${BUNDLE_NAME}.tar.gz" "$BUNDLE_NAME"
            echo "ASSET_PATH=${BUNDLE_NAME}.tar.gz" >> $GITHUB_ENV
          fi
          
          echo "BUNDLE_NAME=${BUNDLE_NAME}" >> $GITHUB_ENV

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BUNDLE_NAME }}
          path: ${{ env.ASSET_PATH }}
          retention-days: 7

      - name: Upload to release
        if: startsWith(github.ref, 'refs/tags/') || github.event_name == 'workflow_dispatch'
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ steps.version.outputs.version }}
          files: ${{ env.ASSET_PATH }}
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Build desktop app
  build-desktop:
    name: Build Desktop App (${{ matrix.os }})
    runs-on: ${{ matrix.runner }}
    needs: create-release
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: linux
            runner: ubuntu-22.04
            build_script: build:linux
            
          - os: macos
            runner: macos-latest
            build_script: build:mac
            
          - os: windows
            runner: windows-latest
            build_script: build:win

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Get version
        id: version
        shell: bash
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "version=${{ github.event.inputs.version }}" >> $GITHUB_OUTPUT
          else
            echo "version=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT
          fi

      - name: Build CLI binaries for bundling
        shell: bash
        run: |
          VERSION="${{ steps.version.outputs.version }}"
          BUILD_TIME=$(date -u '+%Y-%m-%d_%H:%M:%S')
          
          # Build for all platforms that desktop app will need
          mkdir -p build/linux build/macos build/windows
          
          # Linux binary
          GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build \
            -ldflags="-s -w -X main.Version=${VERSION} -X main.BuildTime=${BUILD_TIME}" \
            -o build/linux/offgrid ./cmd/offgrid
          
          # macOS binaries (both architectures)
          GOOS=darwin GOARCH=amd64 CGO_ENABLED=0 go build \
            -ldflags="-s -w -X main.Version=${VERSION} -X main.BuildTime=${BUILD_TIME}" \
            -o build/macos/offgrid-amd64 ./cmd/offgrid
          
          GOOS=darwin GOARCH=arm64 CGO_ENABLED=0 go build \
            -ldflags="-s -w -X main.Version=${VERSION} -X main.BuildTime=${BUILD_TIME}" \
            -o build/macos/offgrid-arm64 ./cmd/offgrid
          
          # Windows binary
          GOOS=windows GOARCH=amd64 CGO_ENABLED=0 go build \
            -ldflags="-s -w -X main.Version=${VERSION} -X main.BuildTime=${BUILD_TIME}" \
            -o build/windows/offgrid.exe ./cmd/offgrid

      - name: Install desktop dependencies
        working-directory: desktop
        run: npm install

      - name: Clean electron-builder cache
        if: matrix.os == 'macos'
        shell: bash
        run: |
          # Remove electron-builder cache that might have old DMG settings
          rm -rf ~/Library/Caches/electron-builder
          rm -rf ~/.cache/electron-builder
          rm -rf desktop/node_modules/dmg-builder/.cache
          echo "Electron-builder cache cleaned"

      - name: Prepare architecture-specific binaries (macOS)
        if: matrix.os == 'macos'
        shell: bash
        run: |
          # List what we have
          ls -la build/macos/
          
          # Electron-builder will build each arch separately, so we'll handle this in the build
          echo "macOS binaries prepared: offgrid-amd64 and offgrid-arm64"

      - name: Build desktop app
        working-directory: desktop
        run: |
          echo "Building desktop app for ${{ matrix.os }}..."
          npm run ${{ matrix.build_script }}
          echo "Build completed. Listing dist directory:"
        shell: bash
          
      - name: List build output
        working-directory: desktop
        shell: bash
        run: |
          if [ -d "dist" ]; then
            echo "Contents of dist/ directory:"
            ls -lah dist/
          else
            echo "dist/ directory not found!"
          fi
          
      - name: Verify build artifacts exist
        continue-on-error: true
        working-directory: desktop/dist
        shell: bash
        run: |
          echo "Checking for build artifacts..."
          ls -la
          
          if [ "${{ matrix.os }}" = "linux" ]; then
            if ! ls *.AppImage *.deb 2>/dev/null | grep -q .; then
              echo "WARNING: No Linux desktop artifacts found!"
            else
              echo "SUCCESS: Found Linux desktop artifacts"
            fi
          elif [ "${{ matrix.os }}" = "macos" ]; then
            if ! ls *.dmg 2>/dev/null | grep -q .; then
              echo "WARNING: No macOS desktop artifacts found!"
            else
              echo "SUCCESS: Found macOS desktop artifacts"
            fi
          elif [ "${{ matrix.os }}" = "windows" ]; then
            if ! ls *.exe 2>/dev/null | grep -q .; then
              echo "WARNING: No Windows desktop artifacts found!"
            else
              echo "SUCCESS: Found Windows desktop artifacts"
            fi
          fi

      - name: Find and upload artifacts
        id: artifacts
        shell: bash
        working-directory: desktop/dist
        run: |
          if [ "${{ matrix.os }}" = "linux" ]; then
            # Upload all Linux artifacts (AppImage and .deb)
            for file in *.AppImage *.deb; do
              if [ -f "$file" ]; then
                echo "Found: $file"
                echo "$file" >> ../../artifacts-list.txt
              fi
            done
          elif [ "${{ matrix.os }}" = "macos" ]; then
            # Upload all macOS artifacts (.dmg files)
            for file in *.dmg; do
              if [ -f "$file" ]; then
                echo "Found: $file"
                echo "$file" >> ../../artifacts-list.txt
              fi
            done
          else
            # Upload all Windows artifacts (.exe installers and portable)
            for file in *.exe; do
              if [ -f "$file" ]; then
                echo "Found: $file"
                echo "$file" >> ../../artifacts-list.txt
              fi
            done
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: desktop-${{ matrix.os }}
          path: desktop/dist/*
          retention-days: 7

      - name: Upload to release
        if: startsWith(github.ref, 'refs/tags/') || github.event_name == 'workflow_dispatch'
        shell: bash
        working-directory: desktop/dist
        run: |
          echo "Current directory contents:"
          ls -lah
          echo ""
          echo "Looking for files to upload..."
          
          # Determine file pattern based on OS
          if [ "${{ matrix.os }}" = "linux" ]; then
            PATTERN="\( -name \"*.AppImage\" -o -name \"*.deb\" \)"
          elif [ "${{ matrix.os }}" = "macos" ]; then
            PATTERN="-name \"*.zip\""
          else
            PATTERN="-name \"*.exe\""
          fi
          
          # Count files first
          FILE_COUNT=0
          if [ "${{ matrix.os }}" = "linux" ]; then
            FILE_COUNT=$(find . -maxdepth 1 \( -name "*.AppImage" -o -name "*.deb" \) -type f | wc -l)
          elif [ "${{ matrix.os }}" = "macos" ]; then
            FILE_COUNT=$(find . -maxdepth 1 -name "*.zip" -type f | wc -l)
          else
            FILE_COUNT=$(find . -maxdepth 1 -name "*.exe" -type f | wc -l)
          fi
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "ERROR: No files found to upload for ${{ matrix.os }}!"
            exit 1
          fi
          
          echo "Found $FILE_COUNT file(s) to upload"
          echo ""
          
          # Upload files using while loop (portable across all shells)
          if [ "${{ matrix.os }}" = "linux" ]; then
            find . -maxdepth 1 \( -name "*.AppImage" -o -name "*.deb" \) -type f | while IFS= read -r filepath; do
              file="${filepath#./}"
              echo "Uploading: $file ($(du -h "$file" | cut -f1))"
              if gh release upload ${{ steps.version.outputs.version }} "$file" --repo ${{ github.repository }} --clobber; then
                echo "âœ“ Successfully uploaded: $file"
              else
                echo "âœ— Failed to upload: $file"
                exit 1
              fi
            done
          elif [ "${{ matrix.os }}" = "macos" ]; then
            find . -maxdepth 1 -name "*.zip" -type f | while IFS= read -r filepath; do
              file="${filepath#./}"
              echo "Uploading: $file ($(du -h "$file" | cut -f1))"
              if gh release upload ${{ steps.version.outputs.version }} "$file" --repo ${{ github.repository }} --clobber; then
                echo "âœ“ Successfully uploaded: $file"
              else
                echo "âœ— Failed to upload: $file"
                exit 1
              fi
            done
          else
            find . -maxdepth 1 -name "*.exe" -type f | while IFS= read -r filepath; do
              file="${filepath#./}"
              echo "Uploading: $file ($(du -h "$file" | cut -f1))"
              if gh release upload ${{ steps.version.outputs.version }} "$file" --repo ${{ github.repository }} --clobber; then
                echo "âœ“ Successfully uploaded: $file"
              else
                echo "âœ— Failed to upload: $file"
                exit 1
              fi
            done
          fi
          
          echo ""
          echo "All files uploaded successfully!"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Create release notes and checksums
  finalize-release:
    name: Finalize Release
    runs-on: ubuntu-latest
    needs: [build-bundles, build-desktop]
    if: startsWith(github.ref, 'refs/tags/') || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Get version
        id: version
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "version=${{ github.event.inputs.version }}" >> $GITHUB_OUTPUT
          else
            echo "version=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT
          fi

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Generate checksums
        run: |
          cd artifacts
          find . -type f \( -name "*.tar.gz" -o -name "*.zip" -o -name "*.AppImage" -o -name "*.dmg" -o -name "*.exe" \) -exec sha256sum {} \; > ../checksums-${{ steps.version.outputs.version }}.sha256
          cd ..

      - name: Create release notes
        run: |
          cat > release-notes.md << EOF
          # OffGrid LLM ${{ steps.version.outputs.version }}
          
          **Complete release with CLI bundles and Desktop applications!**
          
          ## Installation
          
          ### ðŸ–¥ï¸ Desktop Application (Recommended for Most Users)
          
          **Easy installation with system tray integration:**
          
          **Linux:**
          - Download `.AppImage` - Make executable and run: \`chmod +x *.AppImage && ./OffGrid*.AppImage\`
          - Or download \`.deb\` - Install: \`sudo dpkg -i *.deb\`
          
          **macOS:**
          - Download \`.dmg\` - Mount and drag to Applications folder
          
          **Windows:**
          - Download \`*Setup*.exe\` - Run installer
          
          **One-line install:**
          \`\`\`bash
          # Linux/macOS
          curl -fsSL https://raw.githubusercontent.com/takuphilchan/offgrid-llm/main/installers/desktop.sh | bash
          
          # Windows (PowerShell as Admin)
          irm https://raw.githubusercontent.com/takuphilchan/offgrid-llm/main/installers/desktop.ps1 | iex
          \`\`\`
          
          ### ðŸ’» CLI Installation (For Servers & Advanced Users)
          
          **Linux / macOS:**
          \`\`\`bash
          curl -fsSL https://raw.githubusercontent.com/takuphilchan/offgrid-llm/main/install.sh | bash
          \`\`\`
          
          **Or download bundles below and extract**
          
          ## ðŸ“¦ Desktop Applications
          
          ### Linux
          - \`OffGrid-LLM-Desktop-{version}-x86_64.AppImage\` - Universal Linux (recommended)
          - \`OffGrid-LLM-Desktop-{version}-amd64.deb\` - Debian/Ubuntu
          - \`OffGrid-LLM-Desktop-{version}-arm64.AppImage\` - ARM64 Linux
          - \`OffGrid-LLM-Desktop-{version}-arm64.deb\` - ARM64 Debian/Ubuntu
          
          ### macOS  
          - \`OffGrid-LLM-Desktop-{version}-arm64.dmg\` - Apple Silicon (M1/M2/M3)
          - \`OffGrid-LLM-Desktop-{version}-x64.dmg\` - Intel Mac
          - \`OffGrid-LLM-Desktop-{version}-universal.dmg\` - Universal (both architectures)
          
          ### Windows
          - \`OffGrid-LLM-Desktop-Setup-{version}.exe\` - Windows Installer (recommended)
          - \`OffGrid-LLM-Desktop-{version}-Portable.exe\` - Portable version (no install)
          
          ## ðŸ”§ CLI Bundles
          
          Choose your platform and GPU variant:
          
          ### Linux
          - \`offgrid-${{ steps.version.outputs.version }}-linux-amd64-vulkan-avx2.tar.gz\` - Vulkan GPU (recommended, Intel/AMD 2013+)
          - \`offgrid-${{ steps.version.outputs.version }}-linux-amd64-vulkan-avx512.tar.gz\` - Vulkan GPU (newer Intel)
          - \`offgrid-${{ steps.version.outputs.version }}-linux-amd64-cpu-avx2.tar.gz\` - CPU only
          - \`offgrid-${{ steps.version.outputs.version }}-linux-arm64-cpu-neon.tar.gz\` - ARM64
          
          ### macOS
          - \`offgrid-${{ steps.version.outputs.version }}-darwin-arm64-metal-apple-silicon.tar.gz\` - Apple Silicon with Metal GPU
          - \`offgrid-${{ steps.version.outputs.version }}-darwin-amd64-cpu-avx2.tar.gz\` - Intel Mac (CPU only)
          
          ### Windows
          - \`offgrid-${{ steps.version.outputs.version }}-windows-amd64-cpu-avx2.zip\` - CPU only
          
          ## ðŸ“‹ What's Included
          
          ### Desktop App Includes:
          - Beautiful UI with system tray
          - Automatic server management  
          - Built-in CLI binary
          - Model management interface
          - Chat interface
          
          ### CLI Bundle Includes:
          - \`offgrid\` - Main CLI application
          - \`llama-server\` - Inference engine (llama.cpp)
          - \`install.sh\` - Installation script (Linux/macOS)
          - \`README.md\` - Getting started guide
          - \`checksums.sha256\` - File verification
          
          ## âœ… Verification
          
          Verify your download:
          \`\`\`bash
          sha256sum -c checksums-${{ steps.version.outputs.version }}.sha256
          \`\`\`
          
          ## ðŸš€ Getting Started
          
          ### Desktop App
          1. Install using one of the methods above
          2. Launch "OffGrid LLM Desktop" from your applications
          3. Use the Models tab to download models
          4. Start chatting!
          
          ### CLI
          After installation:
          \`\`\`bash
          # Verify
          offgrid --version
          
          # Search for models
          offgrid search llama --limit 5
          
          # Download a model
          offgrid download-hf bartowski/Llama-3.2-3B-Instruct-GGUF \\
            --file Llama-3.2-3B-Instruct-Q4_K_M.gguf
          
          # Start chatting
          offgrid run Llama-3.2-3B-Instruct-Q4_K_M
          
          # Or use Web UI
          open http://localhost:11611/ui
          \`\`\`
          
          ## ðŸ“š Documentation
          
          - [Complete Documentation](https://github.com/takuphilchan/offgrid-llm/tree/main/docs)
          - [Desktop App Guide](https://github.com/takuphilchan/offgrid-llm/blob/main/DESKTOP_INSTALL.md)
          - [CLI Reference](https://github.com/takuphilchan/offgrid-llm/blob/main/docs/CLI_REFERENCE.md)
          - [API Documentation](https://github.com/takuphilchan/offgrid-llm/blob/main/docs/API.md)
          EOF

      - name: Upload checksums to release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ steps.version.outputs.version }}
          files: checksums-${{ steps.version.outputs.version }}.sha256
          body_path: release-notes.md
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
